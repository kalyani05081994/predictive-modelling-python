import pandas as pd
import numpy as np
adult_df=pd.read_csv('C:/Users/00008020/.spyder-py3/python_programs/data_excel_or_csv/adult_data.csv',header=None,delimiter=' *, *',engine='python')
adult_df.head()
#%%
adult_df.shape
#%%creating dataframe
adult_df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',
'marital_status', 'occupation', 'relationship',
'race', 'sex', 'capital_gain', 'capital_loss',
'hours_per_week', 'native_country', 'income']
adult_df.head()
#%%data cleaning
adult_df.isnull().sum()
'''age               0
workclass         0
fnlwgt            0
education         0
education_num     0
marital_status    0
occupation        0
relationship      0
race              0
sex               0
capital_gain      0
capital_loss      0
hours_per_week    0
native_country    0
income            0
dtype: int64''' #this shows we dont have missing values in numerical variables
#%%
for value in['workclass','education','marital_status','occupation','relationship','race','sex','native_country','income']:
    print(value,':',sum(adult_df[value]=='?'))
    #%%creating copy of dataframe
adult_df_rev=pd.DataFrame.copy(adult_df)
adult_df_rev.describe(include='all')   
#%%
#replace the missing values with values in the top row of each column
for value in['workclass','occupation','native_country']:
    adult_df_rev[value].replace(['?'],adult_df_rev[value].mode()[0],inplace=True)
#%%
for value in['workclass','education','marital_status','occupation','relationship','race','sex','native_country','income']:
    print(value,':',sum(adult_df_rev[value]=='?'))
    
#%%
#can use dummy variable for categorization when less categories are there:getdummy()
#for large categories we use label encoding i.e levels
adult_df_rev.workclass.value_counts()
#%%
adult_df_rev.education.value_counts()
#%%
adult_df_rev.marital_status.value_counts()
#%%
adult_df_rev.occupation.value_counts()
#%%
adult_df_rev.relationship.value_counts()
#%%
adult_df_rev.race.value_counts()
#%%
adult_df_rev.sex.value_counts()
#%%
adult_df_rev.native_country.value_counts()
#%%
adult_df_rev.income.value_counts()
#%%
colname=['workclass','education','marital_status',
         'occupation','relationship','race','sex',
         'native_country','income']
#%%for preprocessing data
from sklearn import preprocessing
le={}
for x in colname:
    le[x]=preprocessing.LabelEncoder()
    adult_df_rev[x]=le[x].fit_transform(adult_df_rev.__getattr__(x))
    #adult_df_rev.__getattr__(x):will go to all obs and if __getattr__(x) is nor given
    #it will only consider labels it wont traverse all obs
#%%
adult_df_rev.head()
#0-->  <=50k 
#1-->  >50k
#%%
#creating x and y
x=adult_df_rev.values[:,:-1]#all columns except last,negative indexing
y=adult_df_rev.values[:,-1]#only last column
#%%
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
scaler.fit(x)
x=scaler.transform(x)
#%%
y=y.astype(int)#by default it shoud create int array for y but sometimes it gets 
#converted into object and when object is given to the model it will show errors for 
#levels hence take this precautionary step
#%%
#splitting into training and testing dataset
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=10)
#test_size by default is 0.25 from sklearn
#carefull while passing train and test variable names order
#%%
from sklearn.linear_model import LogisticRegression
#create model
classifier=(LogisticRegression())
#fitting training data to model
classifier.fit(x_train,y_train)
#predicting
y_pred=classifier.predict(x_test)
print(list(zip(y_test,y_pred)))
#%%
#creating confusion matrix
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
cfm=confusion_matrix(y_test,y_pred)
print(cfm)
print("Classification report:")
print(classification_report(y_test,y_pred))
acc=accuracy_score(y_test,y_pred)
print("accuracy of model is:",acc)
'''[[7009  414]
 [1318 1028]]
Classification report:
             precision    recall  f1-score   support

          0       0.84      0.94      0.89      7423
          1       0.71      0.44      0.54      2346

avg / total       0.81      0.82      0.81      9769

accuracy of model is: 0.8227044733340158 '''
#%%adjusting the threshold
y_pred_prob=classifier.predict_proba(x_test)
print(y_pred_prob)
''' [[0.96907821 0.03092179]
 [0.97220422 0.02779578]
 [0.22738179 0.77261821]
 ...
 [0.83296251 0.16703749]
 [0.83680112 0.16319888]
 [0.15715488 0.84284512]]'''
#%%
y_pred_class=[]
for value in y_pred_prob[:,0]:
    if value <0.6:
        y_pred_class.append(1)
    else:
        y_pred_class.append(0)
print(y_pred_class) 
#%%
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
cfm=confusion_matrix(y_test.tolist(),y_pred_class)
print(cfm)
acc=accuracy_score(y_test.tolist(),y_pred_class)
print("accuracy of model is:",acc) 
print("Classification report:") 
print(classification_report(y_test.tolist(),y_pred_class)) 
#%%
for a in np.arange(0,1,0.05):
    predict_mine=np.where(y_pred_prob[:,0]<a,1,0)
    cfm=confusion_matrix(y_test.tolist(),predict_mine)
    total_err=cfm[0,1]+cfm[1,0]
    print("errors at threshold",a,":",total_err,"type 2 error :",\
          cfm[1,0],"type 1 error:",cfm[0,1])
    #%%
from sklearn import metrics
fpr,tpr,threshold=metrics.roc_curve(y_test.tolist(),y_pred_class)
auc=metrics.auc(fpr,tpr)
#%%
import matplotlib.pyplot as plt
plt.title("receiver operating characteristics")
plt.plot(fpr,tpr,'r',label=auc)
plt.legend(loc='lower right')
plt.plot([0,1],[0,1],'g--')
plt.xlim([0,1])   
plt.ylim([0,1])
plt.xlabel('false +ve rate')
plt.ylabel('true +ve rate') 
plt.show()
#more the red line in the plot is towards left better is the model
#%%
#Using cross validation
classifier=(LogisticRegression())
from sklearn import cross_validation
#performing kfold_cross_validation
kfold_cv=cross_validation.KFold(n=len(x_train),n_folds=10)
print(kfold_cv)

#running the model using scoring metric as accuracy
kfold_cv_result=cross_validation.cross_val_score(estimator=classifier,X=x_train,
y=y_train, cv=kfold_cv)
print(kfold_cv_result)
#finding the mean
print(kfold_cv_result.mean())
'''cross-validation to be done only if drastic difference is present between 
accuracies of original model and k-fold validation model'''

'''training k-fold validation model'''
for train_value, test_value in kfold_cv:
    classifier.fit(x_train[train_value], y_train[train_value]).predict(x_train[test_value])


    y_pred=classifier.predict(x_test)
#print(list(zip(Y_test,Y_pred)))
#%%
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
cfm=confusion_matrix(y_test,y_pred)
print(cfm)
acc=accuracy_score(y_test,y_pred)
print("accuracy of model is:",acc) 
print("Classification report:") 
print(classification_report(y_test,y_pred)) 
#%%
x=adult_df_rev.values[:,:-1]#all columns except last,negative indexing
y=adult_df_rev.values[:,-1]#only last column
#%%
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
scaler.fit(x)
x=scaler.transform(x)
#%%
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=10)
#test_size by default is 0.25 from sklearn
#carefull while passing train and test variable names order
#%%
colname=adult_df_rev.columns[:]
#%%
from  sklearn.feature_selection import RFE
rfe=RFE(classifier,7)
model_rfe=rfe.fit(x_train,y_train)
print('num features:',model_rfe.n_features_)
print('selected features:')
print(list(zip(colname,model_rfe.support_)))
print('feature ranking:',model_rfe.ranking_)
#%%
y_pred=model_rfe.predict(x_test)
#%%
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
cfm=confusion_matrix(y_test,y_pred)
print(cfm)
acc=accuracy_score(y_test,y_pred)
print("accuracy of model is:",acc) 
print("Classification report:") 
print(classification_report(y_test,y_pred)) 
#%%
x=adult_df_rev.values[:,:-1]#all columns except last,negative indexing
y=adult_df_rev.values[:,-1]#only last column

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2


test = SelectKBest(score_func=chi2, k=10)
fit1 = test.fit(x,y)

print(fit1.scores_)
print(list(zip(colname,fit1.get_support())))
features = fit1.transform(x)

print(features)
#%%
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
scaler.fit(features)
x=scaler.transform(features)
#%%
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=10)
#%%
from sklearn.linear_model import LogisticRegression
#create model
classifier=(LogisticRegression())
#fitting training data to model
classifier.fit(x_train,y_train)
#predicting
y_pred=classifier.predict(x_test)
print(list(zip(y_test,y_pred)))
#%%
#creating confusion matrix
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
cfm=confusion_matrix(y_test,y_pred)
print(cfm)
print("Classification report:")
print(classification_report(y_test,y_pred))
acc=accuracy_score(y_test,y_pred)
print("accuracy of model is:",acc)
#%%
#outlier manipulation
#outlier detection
import pandas as pd
import numpy as np
adult_df=pd.read_csv('C:/Users/00008020/.spyder-py3/python_programs/data_excel_or_csv/adult_data.csv',header=None,delimiter=' *, *',engine='python')
adult_df.head()
#%%
adult_df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',
'marital_status', 'occupation', 'relationship',
'race', 'sex', 'capital_gain', 'capital_loss',
'hours_per_week', 'native_country', 'income']
adult_df.head()
#%%

adult_df.boxplot(column='age')
plt.show()
#%%
q1=adult_df['age'].quantile(0.25)#first quartile value
q3=adult_df['age'].quantile(0.75)#third quartile value
iqr=q3-q1#interquartile range
low=q1-1.5*iqr#acceptable range
high=q3+1.5*iqr#acceptable range
#%%
adult_df_include=adult_df.loc[(adult_df['age'] >= low) & (adult_df['age'] <= high)]
#meeting acceptable range
#loc:when you access column using label names
#iloc when you want to access using index
adult_df_exclude=adult_df.loc[(adult_df['age'] < low) | (adult_df['age'] > high)]
#not meeting acceptable range
#%%
print(adult_df_include.shape)
print(adult_df_exclude.shape)
#%%
print(high)
#%%
age_mean=int(adult_df_include.age.mean())
print(age_mean)
#%%
adult_df_exclude.age=age_mean
adult_df_exclude.shape
#%%
#getting back original shape of df
adult_df_rev=pd.concat([adult_df_include,adult_df_exclude])#concatenating both dataframes to get original one
adult_df_rev.shape
#%%
#capping approach
adult_df_exclude.loc[adult_df_exclude['age']<low,'age']=low
adult_df_exclude.loc[adult_df_exclude['age']>high,'age']=high



##----------------------------------*-----------------------------------##








    
        






    

    
    
    
 




